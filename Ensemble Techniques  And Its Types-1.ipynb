{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b3aaab-465d-4ba7-bb43-f36fb0dad7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 1\n",
    "\n",
    "Ensemble learning refers to a machine learning approach where several models are trained to address a common problem, and their predictions are combined to enhance the overall performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa03864-4860-4ca7-a140-ce4c50e92fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question2\n",
    "\n",
    "Ensemble methods are ideal for reducing the variance in models, thereby increasing the accuracy of predictions. The variance is eliminated when multiple models are combined to form a single prediction that is chosen from all other possible predictions from the combined models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c36425-a16d-4fa0-979c-6a07a37d4341",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 3\n",
    "\n",
    "Bagging (Bootstrap Aggregating) involves training multiple models independently and combining their predictions through averaging or voting. Boosting, on the other hand, builds models sequentially, where each subsequent model corrects the errors of its predecessor, ultimately creating a strong ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53edcdcb-f4ed-42a7-a6d5-7872188d0e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 4\n",
    "Boosting converts a system of weak learners into a single strong learning system. For example, to identify the cat image, it combines a weak learner that guesses for pointy ears and another learner that guesses for cat-shaped eyes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ede039e-79c1-463c-88c7-e661734b1f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 5\n",
    "\n",
    "Ensemble methods are ideal for reducing the variance in models, thereby increasing the accuracy of predictions. The variance is eliminated when multiple models are combined to form a single prediction that is chosen from all other possible predictions from the combined models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52023de-626f-4bc7-a806-c8ccca510b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 6\n",
    "\n",
    "Ensemble methods offer several advantages over single models, such as improved accuracy and performance, especially for complex and noisy problems. They can also reduce the risk of overfitting and underfitting by balancing the trade-off between bias and variance, and by using different subsets and features of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a96e6c4-ad9c-45a8-80ed-cd499e438f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 7 \n",
    "\n",
    "Take n repeated random samples, with replacement, from the given dataset. ...\n",
    "Calculate the statistic of interest for each of these resamples, e.g. mean, median, standard deviation, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02081a5e-94b7-421d-b119-af66dd93bd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 8\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
